from fastapi import FastAPI, HTTPException, Depends, Header
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel
from typing import Dict, List, Optional, Tuple
import json
import pathlib
import re
import os
import requests
import jwt
import base64
import hashlib
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from supabase import create_client, Client

ROOT = pathlib.Path(__file__).resolve().parents[1]
SAMPLE_PATH = ROOT / "data" / "sample_comments.json"
PROMPTS_DIR = ROOT / "prompts"

# --- simple .env loader (no external deps)
def _load_local_env():
	env_path = ROOT / ".env"
	if not env_path.exists():
		return
	for line in env_path.read_text(encoding="utf-8").splitlines():
		line = line.strip()
		if not line or line.startswith("#"):
			continue
		if "=" in line:
			k, v = line.split("=", 1)
			k = k.strip()
			v = v.strip().strip('"').strip("'")
			os.environ.setdefault(k, v)

_load_local_env()

# Supabase clientåˆæœŸåŒ–
SUPABASE_URL = os.environ.get("SUPABASE_URL", "")
SUPABASE_ANON_KEY = os.environ.get("SUPABASE_ANON_KEY", "")
SUPABASE_JWT_SECRET = os.environ.get("SUPABASE_JWT_SECRET", "")

supabase: Optional[Client] = None
if SUPABASE_URL and SUPABASE_ANON_KEY:
	supabase = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)

# JWTèªè¨¼è¨­å®š
security = HTTPBearer()

# æš—å·åŒ–ã‚­ãƒ¼è¨­å®š
ENCRYPTION_KEY_STR = os.environ.get("ENCRYPTION_KEY", "")

app = FastAPI(title="æ•™æˆã‚³ãƒ¡ãƒ³ãƒˆè‡ªå‹•åŒ–Bot API (MVP)")

# CORSè¨­å®š - Next.jsãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¨±å¯
# ç’°å¢ƒå¤‰æ•°ã§è¨±å¯ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’è¨­å®šå¯èƒ½ï¼ˆæœ¬ç•ªç’°å¢ƒå¯¾å¿œï¼‰
ALLOWED_ORIGINS = os.environ.get("ALLOWED_ORIGINS", "").split(",") if os.environ.get("ALLOWED_ORIGINS") else []
default_origins = [
	"http://localhost:3000",
	"http://localhost:3001",
	"http://127.0.0.1:3000",
	"http://127.0.0.1:3001",
]
allowed_origins = default_origins + [origin.strip() for origin in ALLOWED_ORIGINS if origin.strip()]

app.add_middleware(
	CORSMiddleware,
	allow_origins=allowed_origins,
	allow_credentials=True,
	allow_methods=["*"],
	allow_headers=["*"],
)


# ===========================================
# ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–ãƒ»å¾©å·åŒ–æ©Ÿèƒ½
# ===========================================

class DataEncryption:
	"""AES-256-GCM ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–ãƒ»å¾©å·åŒ–ã‚¯ãƒ©ã‚¹"""

	def __init__(self, key_str: str):
		"""
		Args:
			key_str: æš—å·åŒ–ã‚­ãƒ¼æ–‡å­—åˆ—ï¼ˆSHA-256ã§ãƒãƒƒã‚·ãƒ¥åŒ–ã—ã¦32ãƒã‚¤ãƒˆéµã‚’ç”Ÿæˆï¼‰
		"""
		if not key_str:
			raise ValueError("Encryption key is not set")

		# ã‚­ãƒ¼æ–‡å­—åˆ—ã‚’SHA-256ã§ãƒãƒƒã‚·ãƒ¥åŒ–ã—ã¦32ãƒã‚¤ãƒˆã®éµã‚’ç”Ÿæˆ
		self.key = hashlib.sha256(key_str.encode()).digest()
		self.aesgcm = AESGCM(self.key)

	def encrypt(self, plaintext: str) -> str:
		"""
		ãƒ†ã‚­ã‚¹ãƒˆã‚’æš—å·åŒ–

		Args:
			plaintext: æš—å·åŒ–ã™ã‚‹å¹³æ–‡

		Returns:
			base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæš—å·æ–‡ï¼ˆnonce + ciphertextå½¢å¼ï¼‰
		"""
		if not plaintext:
			return ""

		# 12ãƒã‚¤ãƒˆã®nonceã‚’ç”Ÿæˆï¼ˆGCMãƒ¢ãƒ¼ãƒ‰ã®æ¨å¥¨ã‚µã‚¤ã‚ºï¼‰
		nonce = os.urandom(12)

		# æš—å·åŒ–
		plaintext_bytes = plaintext.encode('utf-8')
		ciphertext = self.aesgcm.encrypt(nonce, plaintext_bytes, None)

		# nonce + ciphertext ã‚’çµåˆã—ã¦base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
		encrypted_data = nonce + ciphertext
		return base64.b64encode(encrypted_data).decode('utf-8')

	def decrypt(self, encrypted_str: str) -> str:
		"""
		æš—å·æ–‡ã‚’å¾©å·åŒ–

		Args:
			encrypted_str: base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæš—å·æ–‡

		Returns:
			å¾©å·åŒ–ã•ã‚ŒãŸå¹³æ–‡
		"""
		if not encrypted_str:
			return ""

		try:
			# base64ãƒ‡ã‚³ãƒ¼ãƒ‰
			encrypted_data = base64.b64decode(encrypted_str)

			# nonceï¼ˆæœ€åˆã®12ãƒã‚¤ãƒˆï¼‰ã¨ciphertextã‚’åˆ†é›¢
			nonce = encrypted_data[:12]
			ciphertext = encrypted_data[12:]

			# å¾©å·åŒ–
			plaintext_bytes = self.aesgcm.decrypt(nonce, ciphertext, None)
			return plaintext_bytes.decode('utf-8')

		except Exception as e:
			raise ValueError(f"Decryption failed: {str(e)}")


# æš—å·åŒ–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åˆæœŸåŒ–
encryption: Optional[DataEncryption] = None
if ENCRYPTION_KEY_STR:
	try:
		encryption = DataEncryption(ENCRYPTION_KEY_STR)
	except Exception as e:
		print(f"Warning: Failed to initialize encryption: {e}")


# ===========================================
# JWTèªè¨¼ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
# ===========================================

async def verify_jwt(credentials: HTTPAuthorizationCredentials = Depends(security)) -> dict:
	"""
	JWTæ¤œè¨¼ã‚’è¡Œã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’è¿”ã™
	æ¤œè¨¼å¤±æ•—æ™‚ã¯401ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
	"""
	token = credentials.credentials

	# JWTæ¤œè¨¼ã‚’ç„¡åŠ¹åŒ–ã™ã‚‹ç’°å¢ƒå¤‰æ•°ï¼ˆé–‹ç™ºç”¨ï¼‰
	if os.environ.get("DISABLE_AUTH", "0") == "1":
		return {"user_id": "dev-user", "email": "dev@example.com"}

	try:
		# SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼
		if not SUPABASE_URL or not SUPABASE_JWT_SECRET:
			raise HTTPException(
				status_code=500,
				detail="Supabase configuration is missing"
			)

		# JWTã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ãƒ»æ¤œè¨¼
		payload = jwt.decode(
			token,
			SUPABASE_JWT_SECRET,
			algorithms=["HS256"],
			audience="authenticated",
			options={"verify_exp": True}
		)

		# ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã‚’å–å¾—
		user_id = payload.get("sub")
		email = payload.get("email")

		if not user_id:
			raise HTTPException(
				status_code=401,
				detail="Invalid token: user_id not found"
			)

		return {
			"user_id": user_id,
			"email": email,
			"payload": payload
		}

	except jwt.ExpiredSignatureError:
		raise HTTPException(
			status_code=401,
			detail="Token has expired"
		)
	except jwt.InvalidTokenError as e:
		raise HTTPException(
			status_code=401,
			detail=f"Invalid token: {str(e)}"
		)
	except Exception as e:
		raise HTTPException(
			status_code=401,
			detail=f"Authentication failed: {str(e)}"
		)


class GenerateOptions(BaseModel):
	length: Optional[int] = 400
	tone: Optional[str] = "æ¸©ã‹ã‚"


class GenerateRequest(BaseModel):
	text: str
	type: str  # 'reflection' | 'final'
	rubric: Optional[Dict[str, int]] = None
	options: Optional[GenerateOptions] = None


class GenerateResponse(BaseModel):
	ai_comment: str
	used_refs: List[str] = []
	tokens: Optional[int] = None
	latency_ms: Optional[int] = None


# è¿½åŠ : ç›´æ¥ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€ãƒ‰ãƒ©ãƒ•ãƒˆï¼‹Rubricã‚’è¿”ã™MVPç”¨
class DirectGenRequest(BaseModel):
	text: str
	type: Optional[str] = "reflection"


# å‚ç…§ä¾‹ç®¡ç†ç”¨ã®ãƒ¢ãƒ‡ãƒ«
class ReferenceExample(BaseModel):
	id: str
	type: str  # 'reflection' | 'final'
	text: str
	tags: List[str]
	source: str


class ReferenceCreateRequest(BaseModel):
	type: str  # 'reflection' | 'final'
	text: str
	tags: List[str]
	source: Optional[str] = "professor_custom"


class ReferenceUpdateRequest(BaseModel):
	type: Optional[str] = None
	text: Optional[str] = None
	tags: Optional[List[str]] = None
	source: Optional[str] = None


class CSVImportRequest(BaseModel):
	csv_data: str  # CSVæ–‡å­—åˆ—


# ===========================================
# PIIæ¤œå‡ºãƒ»ãƒã‚¹ã‚­ãƒ³ã‚°æ©Ÿèƒ½
# ===========================================

class PIIMatch(BaseModel):
	"""PIIæ¤œå‡ºçµæœ"""
	type: str  # 'name', 'student_id', 'email', 'phone'
	text: str
	start: int
	end: int


class PIIDetector:
	"""å€‹äººæƒ…å ±æ¤œå‡ºãƒ»ãƒã‚¹ã‚­ãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""

	def __init__(self):
		# æ—¥æœ¬èªæ°åãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå§“ãƒ»åã®çµ„ã¿åˆã‚ã›ï¼‰
		self.name_pattern = re.compile(
			r'[ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ¶]{1,5}\s*[ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ¶]{1,5}'
		)

		# å­¦ç±ç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ•°å­—ãƒ»è‹±æ•°å­—ã®çµ„ã¿åˆã‚ã›ï¼‰
		self.student_id_pattern = re.compile(
			r'\b[A-Z]?\d{5,10}\b'
		)

		# ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³
		self.email_pattern = re.compile(
			r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
		)

		# é›»è©±ç•ªå·ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒã‚¤ãƒ•ãƒ³æœ‰ç„¡ä¸¡å¯¾å¿œï¼‰
		self.phone_pattern = re.compile(
			r'\b0\d{1,4}[-\s]?\d{1,4}[-\s]?\d{4}\b'
		)

	def detect(self, text: str) -> List[PIIMatch]:
		"""PIIã‚’æ¤œå‡º"""
		matches = []

		# ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æ¤œå‡ºï¼ˆå„ªå…ˆåº¦é«˜ï¼‰
		for match in self.email_pattern.finditer(text):
			matches.append(PIIMatch(
				type='email',
				text=match.group(),
				start=match.start(),
				end=match.end()
			))

		# é›»è©±ç•ªå·æ¤œå‡º
		for match in self.phone_pattern.finditer(text):
			matches.append(PIIMatch(
				type='phone',
				text=match.group(),
				start=match.start(),
				end=match.end()
			))

		# å­¦ç±ç•ªå·æ¤œå‡º
		for match in self.student_id_pattern.finditer(text):
			# ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚„é›»è©±ç•ªå·ã¨é‡è¤‡ã—ãªã„ã‹ãƒã‚§ãƒƒã‚¯
			overlap = any(
				m.start <= match.start() < m.end or m.start < match.end() <= m.end
				for m in matches
			)
			if not overlap:
				matches.append(PIIMatch(
					type='student_id',
					text=match.group(),
					start=match.start(),
					end=match.end()
				))

		# æ°åæ¤œå‡ºï¼ˆå„ªå…ˆåº¦ä½ã€ä»–ã¨é‡è¤‡ã—ãªã„å ´åˆã®ã¿ï¼‰
		for match in self.name_pattern.finditer(text):
			# ä»–ã®PIIã¨é‡è¤‡ã—ãªã„ã‹ãƒã‚§ãƒƒã‚¯
			overlap = any(
				m.start <= match.start() < m.end or m.start < match.end() <= m.end
				for m in matches
			)
			if not overlap:
				# ä¸€èˆ¬çš„ãªå˜èªã‚’é™¤å¤–ï¼ˆç°¡æ˜“ç‰ˆï¼‰
				if match.group() not in ['ç§ã¯', 'è‡ªåˆ†', 'å­¦ç”Ÿ', 'æ•™æˆ', 'å…ˆç”Ÿ']:
					matches.append(PIIMatch(
						type='name',
						text=match.group(),
						start=match.start(),
						end=match.end()
					))

		# ä½ç½®é †ã«ã‚½ãƒ¼ãƒˆ
		matches.sort(key=lambda m: m.start)
		return matches

	def mask(self, text: str, matches: List[PIIMatch]) -> str:
		"""PIIã‚’ãƒã‚¹ã‚­ãƒ³ã‚°"""
		if not matches:
			return text

		# å¾Œã‚ã‹ã‚‰ç½®æ›ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãšã‚Œãªã„ã‚ˆã†ã«ï¼‰
		result = text
		for match in reversed(matches):
			mask_text = {
				'name': '[æ°å]',
				'student_id': '[å­¦ç±ç•ªå·]',
				'email': '[ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹]',
				'phone': '[é›»è©±ç•ªå·]',
			}.get(match.type, '[å€‹äººæƒ…å ±]')

			result = result[:match.start] + mask_text + result[match.end:]

		return result

	def detect_and_mask(self, text: str) -> Tuple[str, List[Dict]]:
		"""PIIæ¤œå‡ºã¨ãƒã‚¹ã‚­ãƒ³ã‚°ã‚’ä¸€æ‹¬å®Ÿè¡Œ
		Returns: (masked_text, detected_pii_list)
		"""
		matches = self.detect(text)
		masked_text = self.mask(text, matches)

		# æ¤œå‡ºçµæœã‚’Dictã«å¤‰æ›
		detected_pii = [
			{
				'type': m.type,
				'text': m.text,
				'start': m.start,
				'end': m.end
			}
			for m in matches
		]

		return masked_text, detected_pii


def load_samples() -> List[Dict]:
	"""
	å‚ç…§ä¾‹ã‚’èª­ã¿è¾¼ã‚€
	å„ªå…ˆé †ä½:
	1. Supabaseã®knowledge_baseãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
	2. ãƒ­ãƒ¼ã‚«ãƒ«ã®sample_comments.jsonã‹ã‚‰èª­ã¿è¾¼ã¿
	3. ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
	"""
	# Supabaseã‹ã‚‰èª­ã¿è¾¼ã‚€
	if supabase:
		try:
			response = supabase.table("knowledge_base").select("reference_id, type, text, tags, source").execute()
			if response.data:
				# Supabaseã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¤‰æ›
				samples = []
				for item in response.data:
					samples.append({
						"id": item.get("reference_id"),
						"type": item.get("type"),
						"text": item.get("text"),
						"tags": item.get("tags", []),
						"source": item.get("source", "professor_examples")
					})
				return samples
		except Exception as e:
			print(f"Supabaseã‹ã‚‰ã®å‚ç…§ä¾‹èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
			# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©¦ã™

	# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
	try:
		if SAMPLE_PATH.exists():
			return json.loads(SAMPLE_PATH.read_text(encoding="utf-8"))
	except Exception as e:
		print(f"ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®å‚ç…§ä¾‹èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")

	# ä¸¡æ–¹å¤±æ•—ã—ãŸå ´åˆã¯ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã™
	return []


def save_samples(samples: List[Dict]) -> None:
	"""
	å‚ç…§ä¾‹ã‚’ä¿å­˜ï¼ˆéæ¨å¥¨ï¼šå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰

	æ³¨æ„: Railwayãªã©ã®ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ãŒã§ããªã„ãŸã‚ã€
	      Supabaseã¸ã®ç›´æ¥ä¿å­˜ã‚’æ¨å¥¨ã—ã¾ã™ã€‚
	"""
	try:
		if SAMPLE_PATH.exists():
			SAMPLE_PATH.write_text(
				json.dumps(samples, ensure_ascii=False, indent=2),
				encoding="utf-8"
			)
	except Exception as e:
		print(f"è­¦å‘Š: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
		# ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¦ã‚‚ã‚¨ãƒ©ãƒ¼ã«ã—ãªã„ï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒå¯¾å¿œï¼‰


def tokenize(s: str) -> List[str]:
	return [t for t in s.replace("\n", " ").replace("ã€", " ").replace("ã€‚", " ").split() if t]


def jaccard(a: List[str], b: List[str]) -> float:
	set_a, set_b = set(a), set(b)
	if not set_a and not set_b:
		return 0.0
	return len(set_a & set_b) / max(1, len(set_a | set_b))


def retrieve_refs(text: str, doc_type: str, k: int = 2) -> List[str]:
	samples = load_samples()
	toks = tokenize(text)
	candidates = [s for s in samples if s.get("type") == ("reflection" if doc_type == "reflection" else "final")]
	scored = sorted(((jaccard(toks, tokenize(c.get("text", ""))), c.get("text", "")) for c in candidates), reverse=True)
	return [t for _, t in scored[:k]]


def load_prompt(doc_type: str) -> str:
	file = "reflection.txt" if doc_type == "reflection" else "final.txt"
	return (PROMPTS_DIR / file).read_text(encoding="utf-8")


def build_comment(req: GenerateRequest) -> GenerateResponse:
	refs = retrieve_refs(req.text, req.type, k=2)
	prefix = "â—‹ " if req.type == "reflection" else ""
	length = req.options.length if req.options else 400
	tone = req.options.tone if req.options else "æ¸©ã‹ã‚"
	rub = req.rubric or {}
	rub_text = ", ".join([f"{k}:{v}" for k, v in rub.items()]) if rub else ""

	intro = f"{prefix}å…¥åŠ›å†…å®¹ã‚’è¸ã¾ãˆã€æ•™æˆã®èªã‚Šå£ã§ä¸‹æ›¸ãã‚’æç¤ºã—ã¾ã™ã€‚"
	rationale = f"{prefix}å‚ç…§ä¾‹ã«ã‚ˆã‚Šæ–‡ä½“ã®ä¸€è²«æ€§ã‚’æ‹…ä¿ã—ã€æ¬¡ã®ä¸€æ­©ã‚’ç¤ºå”†ã—ã¾ã™ã€‚"
	cond = f"{prefix}ç›®å®‰æ–‡å­—æ•°:{length}ï¼ãƒˆãƒ¼ãƒ³:{tone}ã€‚Rubric:{rub_text}" if rub_text else f"{prefix}ç›®å®‰æ–‡å­—æ•°:{length}ï¼ãƒˆãƒ¼ãƒ³:{tone}ã€‚"

	body = "\n".join([intro, rationale, cond])
	if req.type == "final":
		body = "\n".join([
			"å…¨ä½“è©•ä¾¡: å­¦ã³ã®æ¥ç¶šã¨ä»®èª¬ã®ç­‹ãŒè‰¯ã„ã¨æ„Ÿã˜ã¾ã™ã€‚",
			"å¼·ã¿: è¦³å¯Ÿã¨æ„æ€æ±ºå®šã®ä¸€è²«æ€§ã€‚",
			"æ”¹å–„: æ’¤é€€åŸºæº–ã¨å®Ÿè£…é †ã®æ˜ç¢ºåŒ–ã€‚",
			"ç·æ‹¬: ã‚ã‚Šæ–¹ã«ç«‹è„šã—ã€æ¬¡ã®ä¸€æ­©ã‚’å…·ä½“åŒ–ã—ã¾ã—ã‚‡ã†ã€‚",
		])

	return GenerateResponse(ai_comment=body, used_refs=refs, tokens=None, latency_ms=None)


# è¿½åŠ : ç°¡æ˜“Rubricç®—å‡º
RUBRIC_CATEGORIES = ["ç†è§£åº¦", "è«–ç†æ€§", "ç‹¬è‡ªæ€§", "å®Ÿè·µæ€§", "è¡¨ç¾åŠ›"]


def simple_score(text: str) -> Dict[str, any]:
	"""Rubricã‚¹ã‚³ã‚¢ã¨ç†ç”±ã‚’ç”Ÿæˆ"""
	length = len(text)
	has_examples = any(k in text for k in ["å…·ä½“", "äº‹ä¾‹", "ä¾‹ãˆã°", "ç¾å ´", "å®Ÿè£…", "æ¤œè¨¼"])
	first_person = any(k in text for k in ["ç§ã¯", "è‡ªåˆ†", "çµŒé¨“", "å®Ÿä½“é¨“"])
	logical_markers = sum(k in text for k in ["ãªãœ", "ã—ãŸãŒã£ã¦", "ä¸€æ–¹ã§", "ã¤ã¾ã‚Š", "å‰æ", "ä»®èª¬"])
	clarity = sum(text.count(sym) for sym in ["ã€‚", "ã€", "\n"]) > 3
	
	# ã‚¹ã‚³ã‚¢è¨ˆç®—
	score_values = {
		"ç†è§£åº¦": 3 + (1 if logical_markers >= 2 else 0),
		"è«–ç†æ€§": 3 + (1 if logical_markers >= 3 else 0),
		"ç‹¬è‡ªæ€§": 3 + (1 if first_person else 0),
		"å®Ÿè·µæ€§": 3 + (1 if has_examples else 0),
		"è¡¨ç¾åŠ›": 3 + (1 if clarity and length >= 200 else 0),
	}
	
	# ã‚¹ã‚³ã‚¢ã‚’1ã€œ5ã®ç¯„å›²ã«èª¿æ•´
	for k in list(score_values.keys()):
		score_values[k] = max(1, min(5, score_values[k]))
	
	# ç†ç”±ã‚’ç”Ÿæˆï¼ˆã‚ˆã‚Šè©³ç´°ã§å…·ä½“çš„ãªç†ç”±ï¼‰
	reasons = {}
	
	# ç†è§£åº¦
	if logical_markers >= 3:
		reasons["ç†è§£åº¦"] = "è¬›ç¾©ã®é‡è¦æ¦‚å¿µï¼ˆãªãœã€ä»®èª¬ã€å‰æãªã©ï¼‰ã‚’é©åˆ‡ã«ç†è§£ã—ã€è«–ç†çš„ã«æ•´ç†ã•ã‚Œã¦ã„ã¾ã™"
	elif logical_markers >= 2:
		reasons["ç†è§£åº¦"] = "è¬›ç¾©å†…å®¹ã®åŸºæœ¬çš„ãªç†è§£ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚è«–ç†çš„ãªæ•´ç†ã‚’ã•ã‚‰ã«æ·±ã‚ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†"
	else:
		reasons["ç†è§£åº¦"] = "è¬›ç¾©å†…å®¹ã®ç†è§£ã‚’ç¤ºã™è¡¨ç¾ãŒã‚„ã‚„ä¸è¶³ã—ã¦ã„ã¾ã™ã€‚é‡è¦æ¦‚å¿µã‚’æ˜ç¢ºã«ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†"
	
	# è«–ç†æ€§
	if logical_markers >= 3:
		reasons["è«–ç†æ€§"] = "è«–ç†çš„ãªã¤ãªãŒã‚Šï¼ˆã—ãŸãŒã£ã¦ã€ä¸€æ–¹ã§ã€ã¤ã¾ã‚Šãªã©ï¼‰ãŒæ˜ç¢ºã§ã€ä¸»å¼µã¨æ ¹æ‹ ãŒä¸€è²«ã—ã¦ã„ã¾ã™"
	elif logical_markers >= 2:
		reasons["è«–ç†æ€§"] = "è«–ç†çš„ãªã¤ãªãŒã‚ŠãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚ä¸»å¼µã¨æ ¹æ‹ ã®é–¢ä¿‚ã‚’ã‚ˆã‚Šæ˜ç¢ºã«ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†"
	else:
		reasons["è«–ç†æ€§"] = "è«–ç†çš„ãªã¤ãªãŒã‚Šã‚’ç¤ºã™è¡¨ç¾ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ä¸»å¼µã¨æ ¹æ‹ ã®é–¢ä¿‚ã‚’æ•´ç†ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†"
	
	# ç‹¬è‡ªæ€§
	if first_person:
		reasons["ç‹¬è‡ªæ€§"] = "è‡ªèº«ã®çµŒé¨“ã‚„å®Ÿä½“é¨“ï¼ˆç§ã¯ã€è‡ªåˆ†ã€çµŒé¨“ãªã©ï¼‰ãŒæ˜ç¢ºã«ç¤ºã•ã‚Œã¦ãŠã‚Šã€ç‹¬è‡ªã®è¦–ç‚¹ãŒè¦‹ã‚‰ã‚Œã¾ã™"
	else:
		reasons["ç‹¬è‡ªæ€§"] = "è‡ªèº«ã®çµŒé¨“ã‚„è¦–ç‚¹ã‚’ç¤ºã™è¡¨ç¾ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚å®Ÿä½“é¨“ã‚„å…·ä½“ä¾‹ã‚’è¿½åŠ ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†"
	
	# å®Ÿè·µæ€§
	if has_examples:
		reasons["å®Ÿè·µæ€§"] = "å…·ä½“çš„ãªäº‹ä¾‹ã‚„å®Ÿè·µçš„ãªå†…å®¹ï¼ˆå…·ä½“ã€äº‹ä¾‹ã€ç¾å ´ã€å®Ÿè£…ãªã©ï¼‰ãŒè±Šå¯Œã«å«ã¾ã‚Œã¦ãŠã‚Šã€å®Ÿè·µæ€§ãŒé«˜ã„ã§ã™"
	else:
		reasons["å®Ÿè·µæ€§"] = "å…·ä½“çš„ãªäº‹ä¾‹ã‚„å®Ÿè·µçš„ãªå†…å®¹ãŒã‚„ã‚„ä¸è¶³ã—ã¦ã„ã¾ã™ã€‚å®Ÿå‹™ã¸ã®å¿œç”¨ã‚’å…·ä½“çš„ã«ç¤ºã™ã¨è‰¯ã„ã§ã—ã‚‡ã†"
	
	# è¡¨ç¾åŠ›
	if clarity and length >= 500:
		reasons["è¡¨ç¾åŠ›"] = "æ–‡ç« ã®æ§‹é€ ãŒæ˜ç¢ºã§ã€ååˆ†ãªåˆ†é‡ãŒã‚ã‚Šã€ä¼ã‚ã‚Šã‚„ã™ã„è¡¨ç¾ã«ãªã£ã¦ã„ã¾ã™"
	elif clarity and length >= 200:
		reasons["è¡¨ç¾åŠ›"] = "æ–‡ç« ã®æ§‹é€ ã¯æ˜ç¢ºã§ã™ãŒã€ã‚‚ã†å°‘ã—è©³ã—ãå±•é–‹ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†"
	else:
		reasons["è¡¨ç¾åŠ›"] = "æ–‡ç« ã®æ§‹é€ ã‚„æ˜å¿«ã•ã‚’å‘ä¸Šã•ã›ã‚‹ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚æ®µè½åˆ†ã‘ã‚„å…·ä½“ä¾‹ã‚’è¿½åŠ ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†"
	
	# ã‚¹ã‚³ã‚¢ã¨ç†ç”±ã‚’çµåˆã—ãŸè¾æ›¸ã‚’è¿”ã™
	result = {}
	for category in ["ç†è§£åº¦", "è«–ç†æ€§", "ç‹¬è‡ªæ€§", "å®Ÿè·µæ€§", "è¡¨ç¾åŠ›"]:
		result[category] = {
			"score": score_values[category],
			"reason": reasons[category]
		}
	
	return result


# è¿½åŠ : åå°„ç”¨ãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆï¼ˆéLLMï¼‰
_DEF_NEXT_STEP = [
	("ä»®èª¬", "ä»®èª¬â†’æ¤œè¨¼ã®ãƒ«ãƒ¼ãƒ—ã‚’é€±æ¬¡ã§å›ã—ã€æ’¤é€€åŸºæº–ã‚‚ä¸€æ–‡ã§å®šç¾©ã—ã¾ã—ã‚‡ã†ã€‚"),
	("KPI", "å…ˆã«KPIã®å®šç¾©åŸŸã‚’åˆã‚ã›ã€å…¥åŠ›æŒ‡æ¨™ã¨å‡ºåŠ›æŒ‡æ¨™ã‚’åˆ†ã‘ã¦è­°è«–ã—ã¾ã—ã‚‡ã†ã€‚"),
	("é¡§å®¢", "é¡§å®¢ã®å…·ä½“çš„ãªè¡Œå‹•è¦³å¯Ÿã‚’ä¸€ã¤è¿½åŠ ã—ã€ä¾¡å€¤ä»®èª¬ã®ç¢ºåº¦ã‚’é«˜ã‚ã¾ã—ã‚‡ã†ã€‚"),
	("ä¾¡æ ¼", "ä¾¡æ ¼å—å®¹æ€§ã®ä»®èª¬ã‚’ç«‹ã¦ã€å°ã•ãªA/Bã§ä¸€æ¬¡æ¤œè¨¼ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"),
	("çµ„ç¹”", "æ„æ€æ±ºå®šã®è²¬ä»»å¢ƒç•Œã‚’æ˜ç¢ºã«ã—ã€å®Ÿè¡Œã®è©°ã¾ã‚Šã‚’å…ˆã«å¤–ã—ã¾ã—ã‚‡ã†ã€‚"),
]


def summarize_head(text: str, limit: int = 110) -> str:
	clean = re.sub(r"\s+", " ", text)
	clean = clean.replace("\u3000", " ")
	if len(clean) <= limit:
		return clean
	return clean[:limit].rstrip() + "â€¦"


def choose_next_step(text: str) -> str:
	for key, msg in _DEF_NEXT_STEP:
		if key in text:
			return msg
	return "æ¬¡å›ã¯ä»®èª¬ã®å‰æã‚’è¨€èªåŒ–ã—ã€å°ã•ãæ¤œè¨¼ã§ãã‚‹å˜ä½ã«åˆ†è§£ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"


def generate_reflection_draft(text: str, refs: List[str], scores: Dict[str, any]) -> str:
	lead = summarize_head(text)
	insight = "å“²å­¦ã¨ã—ã¦ã®ã€ã‚ã‚Šæ–¹ã€ã¨å®Ÿå‹™ã®å¾€å¾©ã‚’æ„è­˜ã§ãã¦ã„ã¾ã™ã€‚å‚ç…§ä¾‹ã‚’è¸ã¾ãˆã€æ„æ€æ±ºå®šã®è»¸ã‚’ä¸€æ–‡ã§ç½®ãã¾ã—ã‚‡ã†ã€‚"
	if refs:
		insight = "å‚ç…§ä¾‹ã«è¿‘ã„è«–ç‚¹ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚" + insight
	next_step = choose_next_step(text)
	return "\n".join([
		f"â—‹ {lead}",
		f"â—‹ {insight}",
		f"â—‹ {next_step}",
	])


# è¦ç´„æ©Ÿèƒ½: 3å½¢å¼ï¼ˆã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã€ç®‡æ¡æ›¸ãã€æ§‹é€ åŒ–ï¼‰
def call_openai_summary(prompt: str, system_prompt: str = None) -> Tuple[Optional[str], Optional[str]]:
	"""è¦ç´„ç”Ÿæˆç”¨ã®OpenAI APIå‘¼ã³å‡ºã—"""
	if not OPENAI_API_KEY:
		return None, "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
	try:
		messages = []
		if system_prompt:
			messages.append({"role": "system", "content": system_prompt})
		messages.append({"role": "user", "content": prompt})
		
		resp = requests.post(
			"https://api.openai.com/v1/chat/completions",
			headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"},
			json={
				"model": LLM_MODEL,
				"messages": messages,
				"temperature": 0.3,  # è¦ç´„ã¯ä½ã„temperatureã§ä¸€è²«æ€§ã‚’ä¿ã¤
				"max_tokens": 800,
			},
			timeout=30,
		)
		resp.raise_for_status()
		data = resp.json()
		content = data.get("choices", [{}])[0].get("message", {}).get("content")
		return content, None
	except requests.exceptions.Timeout:
		return None, "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: APIæ¥ç¶šãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
	except requests.exceptions.RequestException as e:
		return None, f"APIã‚¨ãƒ©ãƒ¼: {str(e)}"
	except Exception as e:
		return None, f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}"


def generate_summary_llm(text: str) -> Tuple[Dict[str, any], bool]:
	"""LLMã‚’ä½¿ç”¨ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã®è¦ç´„ã‚’è¦ç‚¹ã”ã¨ã«æ•´ç†ã—ãŸå½¢å¼ã§ç”Ÿæˆ
	Returns: (summary_dict, llm_actually_used)
	"""
	if not USE_LLM or not OPENAI_API_KEY:
		return generate_summary_fallback(text), False
	
	try:
		# è¦ç‚¹ã”ã¨ã«æ•´ç†ã•ã‚ŒãŸè¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
		summary_prompt = f"""ä»¥ä¸‹ã®å­¦ç”Ÿãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã‚“ã§ã€è¦ç‚¹ãŒã‚ã‹ã‚‹ã‚ˆã†ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¬ãƒãƒ¼ãƒˆã€‘
{text}

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®å½¢å¼ã§è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„:

[ãƒ¬ãƒãƒ¼ãƒˆã®å…¨ä½“è¦ç´„ï¼š1-2æ®µè½ã§ã€ãƒ¬ãƒãƒ¼ãƒˆã®ç›®çš„ã€ä¸»è¦ãªãƒ†ãƒ¼ãƒã€è«–ç‚¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã€‚ç´„200-300æ–‡å­—ç¨‹åº¦ã€‚]

[ç•ªå·ä»˜ãã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ1ï¸âƒ£, 2ï¸âƒ£, 3ï¸âƒ£...ï¼‰ã§è¦ç‚¹ã‚’æ•´ç†ï¼šãƒ¬ãƒãƒ¼ãƒˆã®ä¸»è¦ãªè«–ç‚¹ã‚„è€ƒå¯Ÿã‚’3-5ã¤ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†ã‘ã¦èª¬æ˜ã™ã‚‹ã€‚
å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®å½¢å¼ï¼š
1ï¸âƒ£ [ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦‹å‡ºã—]

[ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å†…å®¹ï¼š2-3æ–‡ã§èª¬æ˜ã€‚å¿…è¦ã«å¿œã˜ã¦ç®‡æ¡æ›¸ãã‚‚ä½¿ç”¨å¯ã€‚]

æœ€å¾Œã«ã€Œçµè«–ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ï¼š
[çµè«–]
[ãƒ¬ãƒãƒ¼ãƒˆã®çµè«–ã‚„ç·æ‹¬ï¼š1-2æ®µè½ã§ã¾ã¨ã‚ã‚‹ã€‚]

ã€æ³¨æ„äº‹é …ã€‘
- æ–‡ä½“ã¯ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã§çµ±ä¸€ã—ã¦ãã ã•ã„
- é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„æ¦‚å¿µã¯**å¤ªå­—**ã§å¼·èª¿ã—ã¦ãã ã•ã„
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯èª­ã¿ã‚„ã™ãã€è¦ç‚¹ãŒæ˜ç¢ºã«ãªã‚‹ã‚ˆã†ã«æ§‹æˆã—ã¦ãã ã•ã„
- åŸæ–‡ã®é‡è¦ãªè«–ç‚¹ã‚„è€ƒå¯Ÿã‚’æ¼ã‚‰ã•ãšã€ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„
- æ–‡å­—æ•°ã¯åŸæ–‡ã®ç´„1/5ã‹ã‚‰1/8ç¨‹åº¦ã«åœ§ç¸®ã—ã¦ãã ã•ã„
- è¦‹å‡ºã—ã€ŒğŸ“˜è¦ç´„ã€ã¯å«ã‚ãªã„ã§ãã ã•ã„

è¦ç´„ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„:"""
		
		summary_text, error = call_openai_summary(
			summary_prompt,
			system_prompt="ã‚ãªãŸã¯å­¦è¡“çš„ãªè¦ç´„ã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚æ–‡ç« ã®æœ¬è³ªã‚’æ‰ãˆã€è¦ç‚¹ãŒæ˜ç¢ºã§èª­ã¿ã‚„ã™ã„è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ãƒ¬ãƒãƒ¼ãƒˆã®ä¸»è¦ãªè«–ç‚¹ã‚„è€ƒå¯Ÿã‚’æ§‹é€ çš„ã«æ•´ç†ã—ã€èª­è€…ãŒçŸ­æ™‚é–“ã§å†…å®¹ã‚’ç†è§£ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚"
		)
		
		if not summary_text or error:
			return generate_summary_fallback(text), False
		
		# è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
		summary_clean = summary_text.strip()
		
		# ã€ŒğŸ“˜è¦ç´„ã€ã¨ã„ã†è¦‹å‡ºã—ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯å‰Šé™¤
		summary_clean = re.sub(r"^ğŸ“˜è¦ç´„\s*\n\s*\n?", "", summary_clean, flags=re.MULTILINE)
		summary_clean = re.sub(r"ğŸ“˜è¦ç´„\s*\n\s*\n?", "", summary_clean)
		summary_clean = summary_clean.strip()
		
		# æ—¢å­˜ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨ã®äº’æ›æ€§ã®ãŸã‚ã€executiveãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã‚‚å…¨ä½“è¦ç´„ã‚’è¨­å®š
		# æœ€åˆã®æ®µè½ã‚’ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã¨ã—ã¦æŠ½å‡ºï¼ˆç•ªå·ä»˜ãã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å‰ã¾ã§ï¼‰
		executive_match = re.search(r"^(.*?)(?:\n\s*\n1ï¸âƒ£|$)", summary_clean, re.DOTALL)
		if executive_match:
			executive = executive_match.group(1).strip()
		else:
			# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã®200æ–‡å­—
			executive = summary_clean[:200].strip()
		
		# ç®‡æ¡æ›¸ãè¦ç´„ã¯ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¦‹å‡ºã—ã‹ã‚‰æŠ½å‡º
		bullets = []
		section_matches = re.finditer(r"(\d+ï¸âƒ£)\s+([^\n]+)", summary_clean)
		for match in section_matches:
			bullets.append(match.group(2).strip())
		if len(bullets) > 5:
			bullets = bullets[:5]
		
		# æ§‹é€ åŒ–è¦ç´„ã¯ã€ä¸»è¦ãƒ†ãƒ¼ãƒã¨è¦ç‚¹ã‚’æŠ½å‡º
		structured = {
			"ä¸»è¦ãƒ†ãƒ¼ãƒ": executive[:50] if executive else "çµŒå–¶æˆ¦ç•¥ãƒ»å®Ÿè·µçš„è€ƒå¯Ÿ",
			"è¦ç‚¹": executive[:100] if executive else summarize_head(text, limit=100),
			"è€ƒå¯Ÿã®æ·±ã•": "ä¸­ç¨‹åº¦" if len(text) > 500 else "ç°¡æ½”",
			"å®Ÿè·µæ€§": "é«˜" if any(k in text for k in ["å…·ä½“", "äº‹ä¾‹", "ç¾å ´", "å®Ÿè£…"]) else "ä¸­",
		}
		
		# æ–°ã—ã„å½¢å¼ã®è¦ç´„ã‚’è¿”ã™ï¼ˆLLMä½¿ç”¨æˆåŠŸï¼‰
		return {
			"executive": summary_clean,  # å…¨ä½“ã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ
			"bullets": bullets,
			"structured": structured,
			"formatted": summary_clean,  # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿è¦ç´„
		}, True  # LLMãŒæ­£å¸¸ã«ä½¿ç”¨ã•ã‚ŒãŸ
	except Exception as e:
		# ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«æˆ»ã‚‹
		return generate_summary_fallback(text), False


def generate_summary_fallback(text: str) -> Dict[str, any]:
	"""ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“çš„ãªè¦ç´„ç”Ÿæˆï¼ˆLLMä¸ä½¿ç”¨ï¼‰"""
	clean_text = re.sub(r"\s+", " ", text.strip())
	
	# ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ï¼ˆ200æ–‡å­—ç¨‹åº¦ï¼‰
	executive = summarize_head(text, limit=200)
	if len(clean_text) > 200:
		executive += " æœ¬ãƒ¬ãƒãƒ¼ãƒˆã§ã¯ã€å…·ä½“çš„ãªäº‹ä¾‹ã‚„è€ƒå¯Ÿã‚’é€šã˜ã¦ã€å®Ÿè·µçš„ãªè¦–ç‚¹ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚"
	
	# ç®‡æ¡æ›¸ãè¦ç´„ï¼ˆä¸»è¦ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡ºï¼‰
	bullets = []
	sentences = re.split(r"[ã€‚\n]", clean_text)
	key_sentences = [s.strip() for s in sentences if len(s.strip()) > 20][:5]
	for i, sent in enumerate(key_sentences[:5], 1):
		if sent:
			bullets.append(f"{sent}ã€‚")
	
	# æ§‹é€ åŒ–è¦ç´„
	structured = {
		"ä¸»è¦ãƒ†ãƒ¼ãƒ": "çµŒå–¶æˆ¦ç•¥ãƒ»å®Ÿè·µçš„è€ƒå¯Ÿ",
		"è¦ç‚¹": summarize_head(text, limit=100),
		"è€ƒå¯Ÿã®æ·±ã•": "ä¸­ç¨‹åº¦" if len(text) > 500 else "ç°¡æ½”",
		"å®Ÿè·µæ€§": "é«˜" if any(k in text for k in ["å…·ä½“", "äº‹ä¾‹", "ç¾å ´", "å®Ÿè£…"]) else "ä¸­",
	}
	
	# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚æ–°ã—ã„å½¢å¼ã«åˆã‚ã›ã‚‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰
	summary_formatted = f"""{executive}

1ï¸âƒ£ ä¸»è¦ãªè«–ç‚¹

{bullets[0] if bullets else "æœ¬ãƒ¬ãƒãƒ¼ãƒˆã§ã¯ã€çµŒå–¶æˆ¦ç•¥ã«é–¢ã™ã‚‹è€ƒå¯ŸãŒè¡Œã‚ã‚Œã¦ã„ã¾ã™ã€‚"}

2ï¸âƒ£ å®Ÿè·µçš„ãªè¦–ç‚¹

æœ¬ãƒ¬ãƒãƒ¼ãƒˆã§ã¯ã€å…·ä½“çš„ãªäº‹ä¾‹ã‚„è€ƒå¯Ÿã‚’é€šã˜ã¦ã€å®Ÿè·µçš„ãªè¦–ç‚¹ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚

[çµè«–]

{executive}
"""
	
	return {
		"executive": summary_formatted,  # æ–°ã—ã„å½¢å¼ã«å¯¾å¿œ
		"bullets": bullets,
		"structured": structured,
		"formatted": summary_formatted,
	}


def generate_summary(text: str) -> Tuple[Dict[str, any], bool, Optional[str]]:
	"""ãƒ¬ãƒãƒ¼ãƒˆã®è¦ç´„ã‚’3å½¢å¼ã§ç”Ÿæˆï¼ˆå¸¸ã«LLMä½¿ç”¨ï¼‰
	Returns: (summary_dict, llm_used_for_summary, error_message)
	"""
	if not OPENAI_API_KEY:
		error_msg = "è¦ç´„ç”Ÿæˆã«ã¯OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚ç’°å¢ƒå¤‰æ•°OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
		return {
			"executive": error_msg,
			"bullets": [],
			"structured": {},
			"formatted": error_msg,
		}, False, error_msg
	
	if not USE_LLM:
		error_msg = "LLMãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚ç’°å¢ƒå¤‰æ•°USE_LLM=1ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
		return {
			"executive": error_msg,
			"bullets": [],
			"structured": {},
			"formatted": error_msg,
		}, False, error_msg
	
	try:
		summary_result, llm_used = generate_summary_llm(text)
		return summary_result, llm_used, None
	except Exception as e:
		error_msg = f"è¦ç´„ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
		return {
			"executive": error_msg,
			"bullets": [],
			"structured": {},
			"formatted": error_msg,
		}, False, error_msg


# LLMé€£æºï¼ˆOpenAI APIï¼‰: ç’°å¢ƒå¤‰æ•°ã§åˆ¶å¾¡
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
USE_LLM = os.environ.get("USE_LLM", "0") in ("1", "true", "TRUE", "on")
LLM_MODEL = os.environ.get("LLM_MODEL", "gpt-4o-mini")


def build_llm_prompt(text: str, doc_type: str, refs: List[str], scores: Dict[str, any]) -> str:
	base = load_prompt("reflection" if doc_type == "reflection" else "final")
	
	# å‚ç…§ä¾‹ã®æ–‡å­—æ•°ã‚’åˆ†æã—ã¦ã€å¹³å‡æ–‡å­—æ•°ã‚’è¨ˆç®—
	ref_lengths = []
	refs_text_list = []
	ref_details = []  # å„å‚ç…§ä¾‹ã®è©³ç´°æƒ…å ±ï¼ˆæ–‡å­—æ•°ã‚’å«ã‚€ï¼‰
	
	for i, ref in enumerate(refs, 1):
		if ref:
			# JSONã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚ŒãŸæ”¹è¡Œæ–‡å­—ï¼ˆ\\nï¼‰ã‚’å®Ÿéš›ã®æ”¹è¡Œã«å¤‰æ›
			ref_normalized = ref.replace("\\n", "\n")
			# æ”¹è¡Œã¨ç©ºç™½ã‚’é™¤ã„ãŸå®Ÿéš›ã®æ–‡å­—æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆæ—¥æœ¬èªæ–‡å­—æ•°ã‚’æ­£ç¢ºã«æ¸¬å®šï¼‰
			ref_clean = ref_normalized.replace("\n", "").replace(" ", "").replace("\t", "").replace("\\n", "")
			ref_length = len(ref_clean)
			ref_lengths.append(ref_length)
			refs_text_list.append(f"- {ref_normalized}")
			ref_details.append(f"å‚ç…§ä¾‹{i}: {ref_length}æ–‡å­—")
	
	# å‚ç…§ä¾‹ã®å¹³å‡æ–‡å­—æ•°ã‚’è¨ˆç®—ï¼ˆå‚ç…§ä¾‹ãŒã‚ã‚‹å ´åˆï¼‰
	target_length = None
	length_instruction = ""
	avg_length = None
	if ref_lengths:
		avg_length = sum(ref_lengths) / len(ref_lengths)
		# å¹³å‡æ–‡å­—æ•°ã®Â±10%ã®ç¯„å›²ã‚’ç›®æ¨™æ–‡å­—æ•°ã¨ã™ã‚‹ï¼ˆã‚ˆã‚Šå³å¯†ã«ï¼‰
		min_length = max(200, int(avg_length * 0.9))  # æœ€å°200æ–‡å­—
		max_length = int(avg_length * 1.1)
		target_length = f"{min_length}ã€œ{max_length}æ–‡å­—"
		
		# å„å‚ç…§ä¾‹ã®æ–‡å­—æ•°ã‚’æ˜ç¤º
		ref_lengths_text = "ã€".join(ref_details)
		length_instruction = f"""
ã€é‡è¦ï¼šæ–‡å­—æ•°æŒ‡å®šï¼ˆå³å®ˆï¼‰ã€‘
å‚ç…§ä¾‹ã®æ–‡å­—æ•°: {ref_lengths_text}
å‚ç…§ä¾‹ã®å¹³å‡æ–‡å­—æ•°: ç´„{int(avg_length)}æ–‡å­—
ç›®æ¨™æ–‡å­—æ•°: {target_length}ï¼ˆå¹³å‡ã®Â±10%ä»¥å†…ï¼‰

âš ï¸ çµ¶å¯¾ã«å®ˆã£ã¦ãã ã•ã„ï¼š
- å¿…ãšå‚ç…§ä¾‹ã¨åŒã˜ãã‚‰ã„ã®åˆ†é‡ã§ç”Ÿæˆã—ã¦ãã ã•ã„
- å‚ç…§ä¾‹ã®æ–‡å­—æ•°ã‚’å‚è€ƒã«ã€{int(avg_length)}æ–‡å­—å‰å¾Œï¼ˆ{target_length}ã®ç¯„å›²å†…ï¼‰ã§ç”Ÿæˆã™ã‚‹ã“ã¨ãŒæœ€é‡è¦ã§ã™
- å‚ç…§ä¾‹ã¨åŒã˜æ–‡ä½“ãƒ»åŒã˜åˆ†é‡æ„Ÿãƒ»åŒã˜è©³ç´°åº¦ã§ç”Ÿæˆã—ã¦ãã ã•ã„
- çŸ­ã™ãã¦ã‚‚é•·ã™ãã¦ã‚‚ã„ã‘ã¾ã›ã‚“ã€‚å‚ç…§ä¾‹ã®å¹³å‡æ–‡å­—æ•°ï¼ˆ{int(avg_length)}æ–‡å­—ï¼‰ã«ã§ãã‚‹ã ã‘è¿‘ã„åˆ†é‡ã§ç”Ÿæˆã—ã¦ãã ã•ã„
"""
	
	refs_text = "\n".join(refs_text_list) if refs_text_list else "(å‚ç…§ãªã—)"
	
	# scoresã®å½¢å¼ã‚’ç¢ºèªï¼ˆæ–°ã—ã„å½¢å¼: {"score": int, "reason": str} ã¾ãŸã¯ å¤ã„å½¢å¼: intï¼‰
	scores_list = []
	for category in ["ç†è§£åº¦", "è«–ç†æ€§", "ç‹¬è‡ªæ€§", "å®Ÿè·µæ€§", "è¡¨ç¾åŠ›"]:
		value = scores.get(category, {})
		if isinstance(value, dict):
			score_val = value.get("score", 0)
			scores_list.append(f"{category}:{score_val}")
		else:
			scores_list.append(f"{category}:{value}")
	scores_text = ", ".join(scores_list) if scores_list else ""
	
	# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ–‡å­—æ•°æŒ‡å®šéƒ¨åˆ†ã‚’å‹•çš„ã«ç½®æ›
	if target_length:
		# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã®ã€Œæ–‡å­—æ•°: 300ã€œ400æ–‡å­—ã€ãªã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç½®æ›
		# ã‚ˆã‚ŠæŸ”è»Ÿãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼ˆå…¨è§’ãƒ»åŠè§’ã‚³ãƒ­ãƒ³ã€æ³¢ç·šãƒ»ãƒã‚¤ãƒ•ãƒ³ã«å¯¾å¿œï¼‰
		base = re.sub(r"æ–‡å­—æ•°[ï¼š:]\s*å‚ç…§ä¾‹.*?æ–‡å­—", f"æ–‡å­—æ•°: {target_length}", base, flags=re.DOTALL)
		base = re.sub(r"æ–‡å­—æ•°[ï¼š:]\s*\d+[ã€œ~-]\d+æ–‡å­—[ï¼ˆ(].*?[ï¼‰)]?", f"æ–‡å­—æ•°: {target_length}ï¼ˆå‚ç…§ä¾‹ã®åˆ†é‡ã«åˆã‚ã›ã‚‹ï¼‰", base)
		base = re.sub(r"æ–‡å­—æ•°[ï¼š:]\s*\d+[ã€œ~-]\d+æ–‡å­—", f"æ–‡å­—æ•°: {target_length}ï¼ˆå‚ç…§ä¾‹ã®åˆ†é‡ã«åˆã‚ã›ã‚‹ï¼‰", base)
		base = re.sub(r"- æ–‡å­—æ•°[ï¼š:]\s*\d+[ã€œ~-]\d+æ–‡å­—", f"- æ–‡å­—æ•°: {target_length}ï¼ˆå‚ç…§ä¾‹ã®åˆ†é‡ã«åˆã‚ã›ã‚‹ï¼‰", base)
	
	return (
		f"{base}\n\nã€å‚ç…§ä¾‹ï¼ˆæ–‡ä½“ã®ãƒ’ãƒ³ãƒˆãƒ»åˆ†é‡ã®ç›®å®‰ï¼‰ã€‘\n{refs_text}{length_instruction}\n"
		f"ã€Rubricæ‰€æ„Ÿï¼ˆç›®å®‰ï¼‰ã€‘\n{scores_text}\n\n"
		f"ã€å…¥åŠ›ãƒ¬ãƒãƒ¼ãƒˆã€‘\n{text}\n"
	)


def call_openai(prompt: str, max_tokens: int = 500, system_message: str = None) -> Tuple[Optional[str], Optional[str]]:
	"""OpenAI APIã‚’å‘¼ã³å‡ºã—ã€çµæœã¨ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
	Args:
		prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
		max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ500ã€å‚ç…§ä¾‹ã«å¿œã˜ã¦å‹•çš„ã«èª¿æ•´ï¼‰
		system_message: ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ¨™æº–ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
	"""
	if not OPENAI_API_KEY:
		return None, "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
	
	if system_message is None:
		system_message = "ã‚ãªãŸã¯çµŒå–¶æˆ¦ç•¥è«–ã®æ•™æˆã§ã™ã€‚æ•¬æ„ã¨æ¸©ã‹ã•ã‚’ä¿ã¡ã€1ã¤ã®ã¾ã¨ã¾ã£ãŸæ–‡ç« ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
	
	try:
		resp = requests.post(
			"https://api.openai.com/v1/chat/completions",
			headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"},
			json={
				"model": LLM_MODEL,
				"messages": [
					{"role": "system", "content": system_message},
					{"role": "user", "content": prompt},
				],
				"temperature": 0.6,
				"max_tokens": max_tokens,
			},
			timeout=30,
		)
		resp.raise_for_status()
		data = resp.json()
		content = data.get("choices", [{}])[0].get("message", {}).get("content")
		return content, None
	except requests.exceptions.Timeout:
		return None, "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: APIæ¥ç¶šãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
	except requests.exceptions.RequestException as e:
		return None, f"APIã‚¨ãƒ©ãƒ¼: {str(e)}"
	except Exception as e:
		return None, f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}"


@app.post("/generate", response_model=GenerateResponse)
async def generate(req: GenerateRequest, user: dict = Depends(verify_jwt)) -> GenerateResponse:
	return build_comment(req)


# ç›´æ¥ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.post("/generate_direct")
async def generate_direct(req: DirectGenRequest, user: dict = Depends(verify_jwt)):
	doc_type = (req.type or "reflection")

	# 1. PIIæ¤œå‡ºãƒ»ãƒã‚¹ã‚­ãƒ³ã‚°
	pii_detector = PIIDetector()
	masked_text, detected_pii = pii_detector.detect_and_mask(req.text)

	# 2. ãƒã‚¹ã‚­ãƒ³ã‚°å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã§å‡¦ç†ã‚’å®Ÿè¡Œ
	refs = retrieve_refs(masked_text, doc_type, k=2)
	scores = simple_score(masked_text)
	llm_used = False
	llm_error = None
	draft = None
	
	# å‚ç…§ä¾‹ã®å¹³å‡æ–‡å­—æ•°ã‚’è¨ˆç®—ã—ã¦ã€max_tokensã‚’å‹•çš„ã«è¨­å®š
	avg_length = None
	max_tokens = 500  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
	system_message = "ã‚ãªãŸã¯çµŒå–¶æˆ¦ç•¥è«–ã®æ•™æˆã§ã™ã€‚æ•¬æ„ã¨æ¸©ã‹ã•ã‚’ä¿ã¡ã€1ã¤ã®ã¾ã¨ã¾ã£ãŸæ–‡ç« ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
	
	if refs:
		ref_lengths = []
		for ref in refs:
			if ref:
				ref_normalized = ref.replace("\\n", "\n")
				ref_clean = ref_normalized.replace("\n", "").replace(" ", "").replace("\t", "").replace("\\n", "")
				ref_length = len(ref_clean)
				ref_lengths.append(ref_length)
		
		if ref_lengths:
			avg_length = sum(ref_lengths) / len(ref_lengths)
			# æ—¥æœ¬èªã®å ´åˆã€1æ–‡å­—â‰ˆ2ãƒˆãƒ¼ã‚¯ãƒ³ç¨‹åº¦ã€‚å®‰å…¨ã®ãŸã‚å¹³å‡æ–‡å­—æ•°ã®2.5å€ã‚’è¨­å®š
			# æœ€å°500ã€æœ€å¤§2000ã«åˆ¶é™
			calculated_tokens = int(avg_length * 2.5)
			max_tokens = max(500, min(calculated_tokens, 2000))
			
			# system_messageã«æ–‡å­—æ•°ã«é–¢ã™ã‚‹æŒ‡ç¤ºã‚’è¿½åŠ 
			system_message = f"""ã‚ãªãŸã¯çµŒå–¶æˆ¦ç•¥è«–ã®æ•™æˆã§ã™ã€‚æ•¬æ„ã¨æ¸©ã‹ã•ã‚’ä¿ã¡ã€1ã¤ã®ã¾ã¨ã¾ã£ãŸæ–‡ç« ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

é‡è¦ï¼šå‚ç…§ä¾‹ã®å¹³å‡æ–‡å­—æ•°ã¯ç´„{int(avg_length)}æ–‡å­—ã§ã™ã€‚å¿…ãšã“ã®åˆ†é‡ã«åˆã‚ã›ã¦ã€åŒã˜ãã‚‰ã„ã®æ–‡é‡ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"""
	
	# 3. ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆï¼ˆãƒã‚¹ã‚­ãƒ³ã‚°å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰
	if USE_LLM and os.environ.get("OPENAI_API_KEY"):
		prompt = build_llm_prompt(masked_text, doc_type, refs, scores)
		draft, llm_error = call_openai(prompt, max_tokens=max_tokens, system_message=system_message)
		llm_used = draft is not None and llm_error is None
	if not draft:
		if doc_type == "reflection":
			draft = generate_reflection_draft(masked_text, refs, scores)
		else:
			draft = "\n".join([
				"å…¨ä½“è©•ä¾¡: å­¦ã³ã®æ¥ç¶šã¨ä»®èª¬ã®ç­‹ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚",
				"å¼·ã¿: ç¾å ´è¦³å¯Ÿã®å…·ä½“æ€§ã€‚",
				"æ”¹å–„: æŒ‡æ¨™ãƒ»æ’¤é€€åŸºæº–ã®æ˜ç¢ºåŒ–ã€‚",
				"ç·æ‹¬: ã‚ã‚Šæ–¹ã«ç«‹è„šã—ã€æ¬¡ã®ä¸€æ­©ã‚’å…·ä½“åŒ–ã—ã¾ã—ã‚‡ã†ã€‚",
			])

	# 4. è¦ç´„ç”Ÿæˆï¼ˆå¸¸ã«LLMä½¿ç”¨ã€ãƒã‚¹ã‚­ãƒ³ã‚°å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼‰
	summary, summary_llm_used, summary_error = generate_summary(masked_text)

	return {
		"report_id": None,
		"feedback_id": None,
		"ai_comment": draft,
		"rubric": scores,
		"summary": summary,
		"used_refs": refs,
		"llm_used": llm_used,
		"llm_error": llm_error,
		"summary_llm_used": summary_llm_used,  # è¦ç´„ç”Ÿæˆã§LLMãŒä½¿ã‚ã‚ŒãŸã‹
		"summary_error": summary_error,  # è¦ç´„ç”Ÿæˆã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚ã‚Œã°ï¼‰
		"masked_text": masked_text,  # ãƒã‚¹ã‚­ãƒ³ã‚°å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
		"detected_pii": detected_pii,  # æ¤œå‡ºã•ã‚ŒãŸPIIæƒ…å ±
		"pii_count": len(detected_pii),  # æ¤œå‡ºã•ã‚ŒãŸPIIæ•°
	}


@app.get("/")
async def root():
	return {
		"message": "æ•™æˆã‚³ãƒ¡ãƒ³ãƒˆè‡ªå‹•åŒ–Bot API (MVP)",
		"version": "1.0.0",
		"status": "running",
		"endpoints": {
			"health": "/health",
			"generate": "/generate_direct",
			"stats": "/stats",
			"references": "/references"
		}
	}


@app.get("/health")
async def health():
	return {"ok": True}


@app.get("/debug/env")
async def debug_env():
	"""ãƒ‡ãƒãƒƒã‚°ç”¨: ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª"""
	return {
		"DISABLE_AUTH": os.environ.get("DISABLE_AUTH", "not set"),
		"SUPABASE_URL_set": bool(os.environ.get("SUPABASE_URL")),
		"OPENAI_API_KEY_set": bool(os.environ.get("OPENAI_API_KEY")),
		"supabase_connected": supabase is not None
	}


# ===========================================
# æš—å·åŒ–ãƒ»å¾©å·åŒ–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ===========================================

class EncryptRequest(BaseModel):
	text: str


class EncryptResponse(BaseModel):
	encrypted_text: str


class DecryptRequest(BaseModel):
	encrypted_text: str


class DecryptResponse(BaseModel):
	text: str


@app.post("/encrypt", response_model=EncryptResponse)
async def encrypt_text(req: EncryptRequest, user: dict = Depends(verify_jwt)) -> EncryptResponse:
	"""ãƒ†ã‚­ã‚¹ãƒˆã‚’æš—å·åŒ–"""
	if not encryption:
		raise HTTPException(status_code=500, detail="Encryption is not configured")

	try:
		encrypted = encryption.encrypt(req.text)
		return EncryptResponse(encrypted_text=encrypted)
	except Exception as e:
		raise HTTPException(status_code=500, detail=f"Encryption failed: {str(e)}")


@app.post("/decrypt", response_model=DecryptResponse)
async def decrypt_text(req: DecryptRequest, user: dict = Depends(verify_jwt)) -> DecryptResponse:
	"""æš—å·æ–‡ã‚’å¾©å·åŒ–"""
	if not encryption:
		raise HTTPException(status_code=500, detail="Encryption is not configured")

	try:
		decrypted = encryption.decrypt(req.encrypted_text)
		return DecryptResponse(text=decrypted)
	except Exception as e:
		raise HTTPException(status_code=500, detail=f"Decryption failed: {str(e)}")


# ===========================================
# çµ±è¨ˆæƒ…å ±ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ===========================================

class StatsResponse(BaseModel):
	total_feedbacks: int
	avg_rubric_scores: Dict[str, float]
	avg_edit_time_seconds: Optional[float]
	avg_satisfaction_score: Optional[float]


@app.get("/stats", response_model=StatsResponse)
async def get_stats(user: dict = Depends(verify_jwt)) -> StatsResponse:
	"""ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
	if not supabase:
		raise HTTPException(status_code=500, detail="Supabase is not configured")

	user_id = user["user_id"]

	try:
		# feedbacks ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
		response = supabase.table("feedbacks")\
			.select("rubric, edit_time_seconds, satisfaction_score")\
			.eq("user_id", user_id)\
			.execute()

		feedbacks = response.data

		if not feedbacks or len(feedbacks) == 0:
			# ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¼ãƒ­å€¤ã‚’è¿”ã™
			return StatsResponse(
				total_feedbacks=0,
				avg_rubric_scores={
					"ç†è§£åº¦": 0.0,
					"è«–ç†æ€§": 0.0,
					"ç‹¬è‡ªæ€§": 0.0,
					"å®Ÿè·µæ€§": 0.0,
					"è¡¨ç¾åŠ›": 0.0,
				},
				avg_edit_time_seconds=None,
				avg_satisfaction_score=None,
			)

		# ç·æ•°
		total_feedbacks = len(feedbacks)

		# Rubricå¹³å‡ç‚¹æ•°ã‚’è¨ˆç®—
		rubric_sums = {
			"ç†è§£åº¦": 0.0,
			"è«–ç†æ€§": 0.0,
			"ç‹¬è‡ªæ€§": 0.0,
			"å®Ÿè·µæ€§": 0.0,
			"è¡¨ç¾åŠ›": 0.0,
		}
		rubric_counts = {
			"ç†è§£åº¦": 0,
			"è«–ç†æ€§": 0,
			"ç‹¬è‡ªæ€§": 0,
			"å®Ÿè·µæ€§": 0,
			"è¡¨ç¾åŠ›": 0,
		}

		edit_time_sum = 0
		edit_time_count = 0
		satisfaction_sum = 0
		satisfaction_count = 0

		for feedback in feedbacks:
			# Rubricã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆ
			rubric = feedback.get("rubric", {})
			for category in ["ç†è§£åº¦", "è«–ç†æ€§", "ç‹¬è‡ªæ€§", "å®Ÿè·µæ€§", "è¡¨ç¾åŠ›"]:
				if category in rubric:
					rubric_item = rubric[category]
					if isinstance(rubric_item, dict) and "score" in rubric_item:
						score = rubric_item["score"]
						rubric_sums[category] += score
						rubric_counts[category] += 1

			# æ‰‹ç›´ã—æ™‚é–“ã‚’é›†è¨ˆ
			edit_time = feedback.get("edit_time_seconds")
			if edit_time is not None:
				edit_time_sum += edit_time
				edit_time_count += 1

			# æº€è¶³åº¦ã‚’é›†è¨ˆ
			satisfaction = feedback.get("satisfaction_score")
			if satisfaction is not None:
				satisfaction_sum += satisfaction
				satisfaction_count += 1

		# å¹³å‡ã‚’è¨ˆç®—
		avg_rubric_scores = {}
		for category in ["ç†è§£åº¦", "è«–ç†æ€§", "ç‹¬è‡ªæ€§", "å®Ÿè·µæ€§", "è¡¨ç¾åŠ›"]:
			if rubric_counts[category] > 0:
				avg_rubric_scores[category] = round(rubric_sums[category] / rubric_counts[category], 2)
			else:
				avg_rubric_scores[category] = 0.0

		avg_edit_time = round(edit_time_sum / edit_time_count, 2) if edit_time_count > 0 else None
		avg_satisfaction = round(satisfaction_sum / satisfaction_count, 2) if satisfaction_count > 0 else None

		return StatsResponse(
			total_feedbacks=total_feedbacks,
			avg_rubric_scores=avg_rubric_scores,
			avg_edit_time_seconds=avg_edit_time,
			avg_satisfaction_score=avg_satisfaction,
		)

	except Exception as e:
		raise HTTPException(status_code=500, detail=f"Failed to fetch stats: {str(e)}")


# ===========================================
# å‚ç…§ä¾‹ç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
# ===========================================

@app.get("/references")
async def get_references(user: dict = Depends(verify_jwt)):
	"""å…¨ã¦ã®å‚ç…§ä¾‹ã‚’å–å¾—"""
	samples = load_samples()
	return {"references": samples, "count": len(samples)}


@app.get("/references/{reference_id}")
async def get_reference(reference_id: str, user: dict = Depends(verify_jwt)):
	"""ç‰¹å®šã®å‚ç…§ä¾‹ã‚’å–å¾—"""
	samples = load_samples()
	reference = next((s for s in samples if s.get("id") == reference_id), None)
	if not reference:
		return {"error": "å‚ç…§ä¾‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}, 404
	return reference


@app.post("/references")
async def create_reference(req: ReferenceCreateRequest, user: dict = Depends(verify_jwt)):
	"""æ–°ã—ã„å‚ç…§ä¾‹ã‚’ä½œæˆ"""
	if not supabase:
		raise HTTPException(status_code=500, detail="SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

	try:
		# æ–°ã—ã„IDã‚’ç”Ÿæˆï¼ˆprof_custom_XXXXå½¢å¼ï¼‰
		response = supabase.table("knowledge_base").select("reference_id").like("reference_id", "prof_custom_%").execute()
		custom_ids = [item["reference_id"] for item in response.data]

		if custom_ids:
			# æ—¢å­˜ã®ã‚«ã‚¹ã‚¿ãƒ IDã‹ã‚‰æœ€å¤§ã®ç•ªå·ã‚’å–å¾—
			max_num = max([int(id.split("_")[-1]) for id in custom_ids if id.split("_")[-1].isdigit()], default=0)
			new_id = f"prof_custom_{max_num + 1:04d}"
		else:
			new_id = "prof_custom_0001"

		# Supabaseã«æ–°ã—ã„å‚ç…§ä¾‹ã‚’æŒ¿å…¥
		data = {
			"reference_id": new_id,
			"type": req.type,
			"text": req.text,
			"tags": req.tags,
			"source": req.source or "professor_custom"
		}

		insert_response = supabase.table("knowledge_base").insert(data).execute()

		# ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’çµ±ä¸€
		new_reference = {
			"id": new_id,
			"type": req.type,
			"text": req.text,
			"tags": req.tags,
			"source": req.source or "professor_custom"
		}

		return {"success": True, "reference": new_reference}

	except Exception as e:
		raise HTTPException(status_code=500, detail=f"å‚ç…§ä¾‹ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


@app.put("/references/{reference_id}")
async def update_reference(reference_id: str, req: ReferenceUpdateRequest, user: dict = Depends(verify_jwt)):
	"""å‚ç…§ä¾‹ã‚’æ›´æ–°"""
	if not supabase:
		raise HTTPException(status_code=500, detail="SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

	try:
		# æ›´æ–°ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆæŒ‡å®šã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ï¼‰
		update_data = {}
		if req.type is not None:
			update_data["type"] = req.type
		if req.text is not None:
			update_data["text"] = req.text
		if req.tags is not None:
			update_data["tags"] = req.tags
		if req.source is not None:
			update_data["source"] = req.source

		if not update_data:
			raise HTTPException(status_code=400, detail="æ›´æ–°ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

		# Supabaseã§æ›´æ–°
		response = supabase.table("knowledge_base").update(update_data).eq("reference_id", reference_id).execute()

		if not response.data:
			raise HTTPException(status_code=404, detail="å‚ç…§ä¾‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

		# æ›´æ–°å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
		updated = response.data[0]
		reference = {
			"id": updated["reference_id"],
			"type": updated["type"],
			"text": updated["text"],
			"tags": updated.get("tags", []),
			"source": updated.get("source", "")
		}

		return {"success": True, "reference": reference}

	except HTTPException:
		raise
	except Exception as e:
		raise HTTPException(status_code=500, detail=f"å‚ç…§ä¾‹ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


@app.delete("/references/{reference_id}")
async def delete_reference(reference_id: str, user: dict = Depends(verify_jwt)):
	"""å‚ç…§ä¾‹ã‚’å‰Šé™¤"""
	if not supabase:
		raise HTTPException(status_code=500, detail="SupabaseãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

	try:
		# Supabaseã‹ã‚‰å‰Šé™¤
		response = supabase.table("knowledge_base").delete().eq("reference_id", reference_id).execute()

		if not response.data:
			raise HTTPException(status_code=404, detail="å‚ç…§ä¾‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

		return {"success": True, "message": "å‚ç…§ä¾‹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"}

	except HTTPException:
		raise
	except Exception as e:
		raise HTTPException(status_code=500, detail=f"å‚ç…§ä¾‹ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


@app.post("/references/import-csv")
async def import_csv(req: CSVImportRequest, user: dict = Depends(verify_jwt)):
	"""CSVå½¢å¼ã§å‚ç…§ä¾‹ã‚’ä¸€æ‹¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

	CSVå½¢å¼:
	type,text,tags,source
	reflection,"ã‚³ãƒ¡ãƒ³ãƒˆæœ¬æ–‡","ã‚¿ã‚°1,ã‚¿ã‚°2",professor_custom
	"""
	import csv
	import io

	samples = load_samples()
	imported_count = 0
	errors = []

	try:
		# CSVã‚’è§£æ
		csv_reader = csv.DictReader(io.StringIO(req.csv_data))

		for i, row in enumerate(csv_reader, start=1):
			try:
				# å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
				if not row.get("type") or not row.get("text"):
					errors.append(f"è¡Œ{i}: typeã¨textã¯å¿…é ˆã§ã™")
					continue

				# tagsã‚’é…åˆ—ã«å¤‰æ›
				tags_str = row.get("tags", "")
				tags = [t.strip() for t in tags_str.split(",") if t.strip()]

				# æ–°ã—ã„IDã‚’ç”Ÿæˆ
				custom_ids = [s.get("id", "") for s in samples if s.get("id", "").startswith("prof_custom_")]
				if custom_ids:
					max_num = max([int(id.split("_")[-1]) for id in custom_ids if id.split("_")[-1].isdigit()], default=0)
					new_id = f"prof_custom_{max_num + 1 + imported_count:04d}"
				else:
					new_id = f"prof_custom_{imported_count + 1:04d}"

				# æ–°ã—ã„å‚ç…§ä¾‹ã‚’è¿½åŠ 
				new_reference = {
					"id": new_id,
					"type": row["type"],
					"text": row["text"],
					"tags": tags,
					"source": row.get("source", "professor_custom")
				}

				samples.append(new_reference)
				imported_count += 1

			except Exception as e:
				errors.append(f"è¡Œ{i}: {str(e)}")

		# ä¿å­˜
		if imported_count > 0:
			save_samples(samples)

		return {
			"success": True,
			"imported_count": imported_count,
			"errors": errors if errors else None
		}

	except Exception as e:
		return {"error": f"CSVè§£æã‚¨ãƒ©ãƒ¼: {str(e)}"}, 400
